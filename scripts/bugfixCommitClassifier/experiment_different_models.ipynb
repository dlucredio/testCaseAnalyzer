{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to find the best model for the dataset using auto_sklearn.\n",
    "\n",
    "Tested in a clean environment with Python 3.9.16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the packages we used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==1.5.2 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from pandas==1.5.2) (1.24.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from pandas==1.5.2) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from pandas==1.5.2) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas==1.5.2) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm==4.64.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (4.64.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyarrow==10.0.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (10.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from pyarrow==10.0.1) (1.24.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk==3.8.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (3.8.1)\n",
      "Requirement already satisfied: joblib in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from nltk==3.8.1) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from nltk==3.8.1) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from nltk==3.8.1) (2022.10.31)\n",
      "Requirement already satisfied: click in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from nltk==3.8.1) (8.1.3)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn==1.2.0 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from scikit-learn==1.2.0) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from scikit-learn==1.2.0) (1.24.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from scikit-learn==1.2.0) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from scikit-learn==1.2.0) (1.10.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: xgboost==1.7.3 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (1.7.3)\n",
      "Requirement already satisfied: scipy in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from xgboost==1.7.3) (1.10.0)\n",
      "Requirement already satisfied: numpy in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from xgboost==1.7.3) (1.24.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: lightgbm==3.3.4 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (3.3.4)\n",
      "Requirement already satisfied: numpy in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from lightgbm==3.3.4) (1.24.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from lightgbm==3.3.4) (1.2.0)\n",
      "Requirement already satisfied: wheel in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from lightgbm==3.3.4) (0.38.4)\n",
      "Requirement already satisfied: scipy in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from lightgbm==3.3.4) (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm==3.3.4) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm==3.3.4) (1.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: catboost==1.1.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (1.1.1)\n",
      "Requirement already satisfied: matplotlib in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from catboost==1.1.1) (3.6.2)\n",
      "Requirement already satisfied: graphviz in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from catboost==1.1.1) (0.20.1)\n",
      "Requirement already satisfied: plotly in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from catboost==1.1.1) (5.11.0)\n",
      "Requirement already satisfied: six in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from catboost==1.1.1) (1.16.0)\n",
      "Requirement already satisfied: scipy in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from catboost==1.1.1) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from catboost==1.1.1) (1.24.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from catboost==1.1.1) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from pandas>=0.24.0->catboost==1.1.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from pandas>=0.24.0->catboost==1.1.1) (2022.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib->catboost==1.1.1) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib->catboost==1.1.1) (9.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib->catboost==1.1.1) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib->catboost==1.1.1) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib->catboost==1.1.1) (4.38.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib->catboost==1.1.1) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib->catboost==1.1.1) (1.4.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from plotly->catboost==1.1.1) (8.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn==0.12.2 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from seaborn==0.12.2) (1.24.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from seaborn==0.12.2) (3.6.2)\n",
      "Requirement already satisfied: pandas>=0.25 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from seaborn==0.12.2) (1.5.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.2) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.2) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.2) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.2) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.2) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.2) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.2) (9.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.2) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from pandas>=0.25->seaborn==0.12.2) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn==0.12.2) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib==3.6.2 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (3.6.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib==3.6.2) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib==3.6.2) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.19 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib==3.6.2) (1.24.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib==3.6.2) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib==3.6.2) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib==3.6.2) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib==3.6.2) (23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib==3.6.2) (1.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from matplotlib==3.6.2) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib==3.6.2) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# To perform data manipulation\n",
    "%pip install pandas==1.5.2\n",
    "\n",
    "# To monitor progress in long tasks\n",
    "%pip install tqdm==4.64.1\n",
    "\n",
    "# Pyarrow is used by pandas to save/load parquet files\n",
    "%pip install pyarrow==10.0.1\n",
    "\n",
    "# To process natural text\n",
    "%pip install nltk==3.8.1\n",
    "\n",
    "# Machine learning algorithms\n",
    "%pip install scikit-learn==1.2.0\n",
    "%pip install xgboost==1.7.3\n",
    "%pip install lightgbm==3.3.4\n",
    "%pip install catboost==1.1.1\n",
    "\n",
    "# To visualize confusion matrix and plot other data\n",
    "%pip install seaborn==0.12.2\n",
    "%pip install matplotlib==3.6.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import the necessary modules and configure a random_state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/daniel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/daniel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from time import time # To measure training times\n",
    "\n",
    "import pandas as pd # For data processing\n",
    "import numpy as np # For data processing\n",
    "\n",
    "import nltk # For text processing\n",
    "nltk.download('stopwords') # Stop words\n",
    "nltk.download('punkt') # Tokenizer\n",
    "english_stop_words = set(nltk.corpus.stopwords.words('english')) # Saving the stopwords in a list\n",
    "\n",
    "from tqdm import tqdm # To monitor progress in large tasks\n",
    "tqdm.pandas() # Configure tqdm to work with pandas\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer # To make sklearn work with text features\n",
    "from sklearn.model_selection import train_test_split # To split train/test data\n",
    "from sklearn.utils import resample # To balance the dataset\n",
    "\n",
    "from sklearn.metrics import classification_report # To determine the quality of our models\n",
    "from sklearn.metrics import confusion_matrix  # To determine the quality of our models\n",
    "import seaborn as sns # To see the confusion matrix\n",
    "import matplotlib.pyplot as plt # To see the confusion matrix\n",
    "\n",
    "# We will try all the following models\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import (RandomForestClassifier,\n",
    "                              AdaBoostClassifier,\n",
    "                              GradientBoostingClassifier)\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "random_state_value=42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our dataset, making sure there are no duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 452284\n",
      "Number of duplicated: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>_id</th>\n",
       "      <th>revision_hash</th>\n",
       "      <th>message</th>\n",
       "      <th>isBugfix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5bef24dc83ad2f56ca1ca7cd</td>\n",
       "      <td>64185d21b51d1ed32c419f443f804ae2e09ee5f8</td>\n",
       "      <td>The the patrol.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5bef24dd83ad2f56ca1ca7d3</td>\n",
       "      <td>37ab026c576c8841f378cc2376ca02c478567e84</td>\n",
       "      <td>Cleanup in commons-rdf-rdf4j to close PMD and ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5bef24dd83ad2f56cb1ca7cd</td>\n",
       "      <td>092c465f996f3a4a6acf3f65aeb76f768e702289</td>\n",
       "      <td>COMMONSRDF-49: Make AbstractRDFParser serializ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5bef24dd83ad2f56cc1ca7cd</td>\n",
       "      <td>6123c7308ed533b870370c6a234ce140368ccc4e</td>\n",
       "      <td>ensure site build works with newest checkstyle...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5bef24dd83ad2f56cc1ca7d4</td>\n",
       "      <td>25af8121afb778efa20d73e1f10c073ad1917e59</td>\n",
       "      <td>[maven-release-plugin] prepare for next develo...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                       _id                             revision_hash  \\\n",
       "0      0  5bef24dc83ad2f56ca1ca7cd  64185d21b51d1ed32c419f443f804ae2e09ee5f8   \n",
       "1      1  5bef24dd83ad2f56ca1ca7d3  37ab026c576c8841f378cc2376ca02c478567e84   \n",
       "2      2  5bef24dd83ad2f56cb1ca7cd  092c465f996f3a4a6acf3f65aeb76f768e702289   \n",
       "3      3  5bef24dd83ad2f56cc1ca7cd  6123c7308ed533b870370c6a234ce140368ccc4e   \n",
       "4      4  5bef24dd83ad2f56cc1ca7d4  25af8121afb778efa20d73e1f10c073ad1917e59   \n",
       "\n",
       "                                             message  isBugfix  \n",
       "0                                    The the patrol.     False  \n",
       "1  Cleanup in commons-rdf-rdf4j to close PMD and ...     False  \n",
       "2  COMMONSRDF-49: Make AbstractRDFParser serializ...     False  \n",
       "3  ensure site build works with newest checkstyle...     False  \n",
       "4  [maven-release-plugin] prepare for next develo...     False  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_commits_annotated = pd.read_parquet('commits_annotated.parquet.gzip')\n",
    "print(f'Number of rows: {df_commits_annotated.shape[0]}')\n",
    "print(f'Number of duplicated: {df_commits_annotated.revision_hash.duplicated().sum()}')\n",
    "df_commits_annotated.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need columns 'message' and 'isBugfix'. Let's drop the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>message</th>\n",
       "      <th>isBugfix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The the patrol.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cleanup in commons-rdf-rdf4j to close PMD and ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>COMMONSRDF-49: Make AbstractRDFParser serializ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ensure site build works with newest checkstyle...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[maven-release-plugin] prepare for next develo...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            message  isBugfix\n",
       "0      0                                    The the patrol.     False\n",
       "1      1  Cleanup in commons-rdf-rdf4j to close PMD and ...     False\n",
       "2      2  COMMONSRDF-49: Make AbstractRDFParser serializ...     False\n",
       "3      3  ensure site build works with newest checkstyle...     False\n",
       "4      4  [maven-release-plugin] prepare for next develo...     False"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_commits_annotated.drop(columns=['_id','revision_hash'], inplace=True)\n",
    "df_commits_annotated.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to balance the dataset. As it can be seen, it is highly imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    449379\n",
       "True       2905\n",
       "Name: isBugfix, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_commits_count = df_commits_annotated['isBugfix'].value_counts()\n",
    "df_commits_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's downsample the majority class. It's okay, since we still have almost 3K \"True\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2905\n",
       "True     2905\n",
       "Name: isBugfix, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_majority = df_commits_annotated[df_commits_annotated.isBugfix==False]\n",
    "df_minority = df_commits_annotated[df_commits_annotated.isBugfix==True]\n",
    "\n",
    "count_minority = df_commits_count[1] # Number of elements in minority class\n",
    "\n",
    "df_majority_downsampled = resample(df_majority,\n",
    "                                    replace=False,\n",
    "                                    n_samples=count_minority,\n",
    "                                    random_state=random_state_value)\n",
    "\n",
    "df_commits_annotated = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "df_commits_annotated['isBugfix'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's preprocess our text. First, we will lowercase and remove stopwords. This will be our 'input_feature' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5810/5810 [00:02<00:00, 2692.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>message</th>\n",
       "      <th>isBugfix</th>\n",
       "      <th>input_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151859</th>\n",
       "      <td>151859</td>\n",
       "      <td>Update installation for impatient\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>update installation impatient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332572</th>\n",
       "      <td>332572</td>\n",
       "      <td>Added example for using the reverse mapping to...</td>\n",
       "      <td>False</td>\n",
       "      <td>added example using reverse mapping tool git-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196656</th>\n",
       "      <td>196656</td>\n",
       "      <td>PDFBOX-2883: remove COSDocument constructors u...</td>\n",
       "      <td>False</td>\n",
       "      <td>pdfbox-2883 : remove cosdocument constructors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395182</th>\n",
       "      <td>395182</td>\n",
       "      <td>Added #else formatting test.\\nPR:\\nObtained fr...</td>\n",
       "      <td>False</td>\n",
       "      <td>added # else formatting test . pr : obtained :...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141552</th>\n",
       "      <td>141552</td>\n",
       "      <td>KAFKA-3740: Part I: expose StreamConfig proper...</td>\n",
       "      <td>False</td>\n",
       "      <td>kafka-3740 : part : expose streamconfig proper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                            message  isBugfix  \\\n",
       "151859  151859                Update installation for impatient\\n     False   \n",
       "332572  332572  Added example for using the reverse mapping to...     False   \n",
       "196656  196656  PDFBOX-2883: remove COSDocument constructors u...     False   \n",
       "395182  395182  Added #else formatting test.\\nPR:\\nObtained fr...     False   \n",
       "141552  141552  KAFKA-3740: Part I: expose StreamConfig proper...     False   \n",
       "\n",
       "                                            input_feature  \n",
       "151859                      update installation impatient  \n",
       "332572  added example using reverse mapping tool git-s...  \n",
       "196656  pdfbox-2883 : remove cosdocument constructors ...  \n",
       "395182  added # else formatting test . pr : obtained :...  \n",
       "141552  kafka-3740 : part : expose streamconfig proper...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lower_case_and_remove_stopwords(text):\n",
    "    return ' '.join([word for word in nltk.tokenize.word_tokenize(text) if word not in (english_stop_words)])\n",
    "\n",
    "df_commits_annotated['input_feature'] = df_commits_annotated['message']\\\n",
    "    .str.lower().progress_apply(lower_case_and_remove_stopwords)\n",
    "df_commits_annotated.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our 'isBugfix' column needs to be converted from boolean to int: True=1, False=0. This will be our 'target' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5810/5810 [00:00<00:00, 459461.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>message</th>\n",
       "      <th>isBugfix</th>\n",
       "      <th>input_feature</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151859</th>\n",
       "      <td>151859</td>\n",
       "      <td>Update installation for impatient\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>update installation impatient</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332572</th>\n",
       "      <td>332572</td>\n",
       "      <td>Added example for using the reverse mapping to...</td>\n",
       "      <td>False</td>\n",
       "      <td>added example using reverse mapping tool git-s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196656</th>\n",
       "      <td>196656</td>\n",
       "      <td>PDFBOX-2883: remove COSDocument constructors u...</td>\n",
       "      <td>False</td>\n",
       "      <td>pdfbox-2883 : remove cosdocument constructors ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395182</th>\n",
       "      <td>395182</td>\n",
       "      <td>Added #else formatting test.\\nPR:\\nObtained fr...</td>\n",
       "      <td>False</td>\n",
       "      <td>added # else formatting test . pr : obtained :...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141552</th>\n",
       "      <td>141552</td>\n",
       "      <td>KAFKA-3740: Part I: expose StreamConfig proper...</td>\n",
       "      <td>False</td>\n",
       "      <td>kafka-3740 : part : expose streamconfig proper...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                            message  isBugfix  \\\n",
       "151859  151859                Update installation for impatient\\n     False   \n",
       "332572  332572  Added example for using the reverse mapping to...     False   \n",
       "196656  196656  PDFBOX-2883: remove COSDocument constructors u...     False   \n",
       "395182  395182  Added #else formatting test.\\nPR:\\nObtained fr...     False   \n",
       "141552  141552  KAFKA-3740: Part I: expose StreamConfig proper...     False   \n",
       "\n",
       "                                            input_feature  target  \n",
       "151859                      update installation impatient       0  \n",
       "332572  added example using reverse mapping tool git-s...       0  \n",
       "196656  pdfbox-2883 : remove cosdocument constructors ...       0  \n",
       "395182  added # else formatting test . pr : obtained :...       0  \n",
       "141552  kafka-3740 : part : expose streamconfig proper...       0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_commits_annotated['target'] = df_commits_annotated['isBugfix']\\\n",
    "    .progress_apply(lambda x: 1 if x else 0)\n",
    "df_commits_annotated.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's split the dataset into train, validation and test, transforming the textual column into vectors in the way.\n",
    "\n",
    "We will try with two vectorizers: CountVectorizer and TfidfVectorizer, for which parameters were copied from the results of [another notebook](find_vectorizer_parameters.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_sub_count shape: (4066, 16830)\n",
      "X_valid_count shape: (872, 16830)\n",
      "X_test_count shape: (872, 16830)\n",
      "X_train_sub_tfidf shape: (4066, 920)\n",
      "X_valid_tfidf shape: (872, 920)\n",
      "X_test_tfidf shape: (872, 920)\n"
     ]
    }
   ],
   "source": [
    "y = df_commits_annotated['target'] # target\n",
    "test_valid_percentage = 0.15 # This means 15% test, 15% validation, 70% training\n",
    "\n",
    "# Count Vectorizer\n",
    "vect_count = CountVectorizer()\n",
    "X_count = vect_count.fit_transform(df_commits_annotated['input_feature'])\n",
    "X_train_count, X_test_count, y_train_count, y_test_count = train_test_split(X_count, y, test_size=test_valid_percentage, random_state=random_state_value)\n",
    "X_train_sub_count, X_valid_count, y_train_sub_count, y_valid_count = train_test_split(X_train_count, y_train_count, test_size=test_valid_percentage/(1-test_valid_percentage), random_state=random_state_value)\n",
    "\n",
    "print('X_train_sub_count shape:', X_train_sub_count.shape)\n",
    "print('X_valid_count shape:', X_valid_count.shape)\n",
    "print('X_test_count shape:', X_test_count.shape)\n",
    "\n",
    "# TF-IDF Vectorizer\n",
    "vect_tfidf = TfidfVectorizer(encoding='latin-1', max_df=0.23622995216793718,\n",
    "                max_features=920, min_df=2, ngram_range=(1, 3),\n",
    "                sublinear_tf=True, token_pattern='\\\\w{1,}')\n",
    "\n",
    "X_tfidf = vect_tfidf.fit_transform(df_commits_annotated['input_feature'])\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, y, test_size=test_valid_percentage, random_state=random_state_value)\n",
    "X_train_sub_tfidf, X_valid_tfidf, y_train_sub_tfidf, y_valid_tfidf = train_test_split(X_train_tfidf, y_train_tfidf, test_size=test_valid_percentage/(1-test_valid_percentage), random_state=random_state_value)\n",
    "\n",
    "print('X_train_sub_tfidf shape:', X_train_sub_tfidf.shape)\n",
    "print('X_valid_tfidf shape:', X_valid_tfidf.shape)\n",
    "print('X_test_tfidf shape:', X_test_tfidf.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring the classifiers. Starting with the one found by sklearn in [another notebook](find_best_model_with_automl.ipynb) and trying some other known ones as suggested by [this article](https://towardsdatascience.com/boosting-showdown-scikit-learn-vs-xgboost-vs-lightgbm-vs-catboost-in-sentiment-classification-f7c7f46fd956)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=12, random_state=random_state_value)\n",
    "rf = RandomForestClassifier(n_estimators=500,\n",
    "                            max_features=0.06,\n",
    "                            n_jobs=6,\n",
    "                            random_state=random_state_value)\n",
    "base_estim = DecisionTreeClassifier(max_depth=1, max_features=0.06)\n",
    "ab = AdaBoostClassifier(base_estimator=base_estim,\n",
    "                        n_estimators=500,\n",
    "                        learning_rate=0.5,\n",
    "                        random_state=random_state_value)\n",
    "gb = GradientBoostingClassifier(n_estimators=2000,\n",
    "                                 subsample=0.67,\n",
    "                                 max_features=0.06,\n",
    "                                 validation_fraction=0.1,\n",
    "                                 n_iter_no_change=15,\n",
    "                                 verbose=0,\n",
    "                                 random_state=random_state_value)\n",
    "xgb = XGBClassifier(n_estimators=2000,\n",
    "                    tree_method='hist',\n",
    "                    subsample=0.67,\n",
    "                    colsample_level=0.06,\n",
    "                    verbose=0,\n",
    "                    n_jobs=6,\n",
    "                    random_state=random_state_value)\n",
    "cb = CatBoostClassifier(n_estimators=2000,\n",
    "                        colsample_bylevel=0.06,\n",
    "                        max_leaves=31,\n",
    "                        subsample=0.67,\n",
    "                        verbose=0,\n",
    "                        thread_count=6,\n",
    "                        random_state=random_state_value)\n",
    "svc = LinearSVC()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a list to store all models and model names, to allow an easy comparison. We will also store which ones require early stop in the `fit()` method, and which ones can use text as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [pac, dt, rf, ab, gb, xgb, cb, svc, cbt]\n",
    "models = [\n",
    "    {\n",
    "        'clf': dt,\n",
    "        'name': 'DecisionTree',\n",
    "        'earlyStop': False,\n",
    "    },\n",
    "    {\n",
    "        'clf': rf,\n",
    "        'name': 'RandomForest',\n",
    "        'earlyStop': False,\n",
    "    },\n",
    "    {\n",
    "        'clf': ab,\n",
    "        'name': 'AdaBoost',\n",
    "        'earlyStop': False,\n",
    "    },\n",
    "    {\n",
    "        'clf': gb,\n",
    "        'name': 'GradientBoosting',\n",
    "        'earlyStop': False,\n",
    "    },\n",
    "    {\n",
    "        'clf': xgb,\n",
    "        'name': 'XGB',\n",
    "        'earlyStop': True,\n",
    "    },\n",
    "    {\n",
    "        'clf': cb,\n",
    "        'name': 'CatBoost',\n",
    "        'earlyStop': True,\n",
    "    },\n",
    "    {\n",
    "        'clf': svc,\n",
    "        'name': 'LinearSVC',\n",
    "        'earlyStop': False,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train each model. First we create a DataFrame to store the results and then we loop through all of them, recording time and accuracy. We will do the same for both vectorized data: with CountVectorizer and TfidfVectorizer\n",
    "\n",
    "On my machine (a core i7-3770 CPU @ 3.40GHz with no GPU and 12Gb of RAM) this takes around 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:23:23] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"colsample_level\", \"verbose\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/home/daniel/.pyenv/versions/3.9.16/envs/testcaseanalyzer/lib/python3.9/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:24:25] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"colsample_level\", \"verbose\" } are not used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# First, with CountVectorizer\n",
    "for m in models:\n",
    "    clf = m['clf']\n",
    "    start_time = time()\n",
    "    if m['earlyStop']:\n",
    "        clf.fit(X_train_sub_count,\n",
    "                y_train_sub_count,\n",
    "                eval_set = [(X_valid_count, y_valid_count)],\n",
    "                early_stopping_rounds=15,\n",
    "                verbose=0)\n",
    "    else:\n",
    "        clf.fit(X_train_count, y_train_count)\n",
    "\n",
    "    run_time = time() - start_time\n",
    "    accuracy = np.mean(clf.predict(X_test_count) == y_test_count)\n",
    "    y_pred = clf.predict(X_test_count)\n",
    "    report = classification_report(y_test_count, y_pred)\n",
    "\n",
    "\n",
    "    results.append({\n",
    "        'model': m['name'],\n",
    "        'vectorizer': 'CountVectorizer',\n",
    "        'accuracy': accuracy,\n",
    "        'runtime': 'run_time',\n",
    "        'report': report\n",
    "    })\n",
    "\n",
    "# Next, with TfidfVectorizer\n",
    "for m in models:\n",
    "    clf = m['clf']\n",
    "    start_time = time()\n",
    "    if m['earlyStop']:\n",
    "        clf.fit(X_train_sub_tfidf,\n",
    "                y_train_sub_tfidf,\n",
    "                eval_set = [(X_valid_tfidf, y_valid_tfidf)],\n",
    "                early_stopping_rounds=15,\n",
    "                verbose=0)\n",
    "    else:\n",
    "        clf.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "    run_time = time() - start_time\n",
    "    accuracy = np.mean(clf.predict(X_test_tfidf) == y_test_tfidf)\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    report = classification_report(y_test_tfidf, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        'model': m['name'],\n",
    "        'vectorizer': 'TfIdfVectorizer',\n",
    "        'accuracy': accuracy,\n",
    "        'runtime': 'run_time',\n",
    "        'report': report\n",
    "    })\n",
    "\n",
    "dfResults = pd.DataFrame(results, columns=['model','vectorizer','accuracy','runtime','report'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print detailed classification scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "XGB   CountVectorizer\n",
      "============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       455\n",
      "           1       0.95      0.99      0.97       417\n",
      "\n",
      "    accuracy                           0.97       872\n",
      "   macro avg       0.97      0.97      0.97       872\n",
      "weighted avg       0.97      0.97      0.97       872\n",
      "\n",
      "============================\n",
      "LinearSVC   CountVectorizer\n",
      "============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       455\n",
      "           1       0.96      0.98      0.97       417\n",
      "\n",
      "    accuracy                           0.97       872\n",
      "   macro avg       0.97      0.97      0.97       872\n",
      "weighted avg       0.97      0.97      0.97       872\n",
      "\n",
      "============================\n",
      "GradientBoosting   CountVectorizer\n",
      "============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       455\n",
      "           1       0.94      0.98      0.96       417\n",
      "\n",
      "    accuracy                           0.96       872\n",
      "   macro avg       0.96      0.96      0.96       872\n",
      "weighted avg       0.96      0.96      0.96       872\n",
      "\n",
      "============================\n",
      "CatBoost   CountVectorizer\n",
      "============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       455\n",
      "           1       0.94      0.98      0.96       417\n",
      "\n",
      "    accuracy                           0.96       872\n",
      "   macro avg       0.96      0.96      0.96       872\n",
      "weighted avg       0.96      0.96      0.96       872\n",
      "\n",
      "============================\n",
      "LinearSVC   TfIdfVectorizer\n",
      "============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       455\n",
      "           1       0.93      0.98      0.96       417\n",
      "\n",
      "    accuracy                           0.96       872\n",
      "   macro avg       0.96      0.96      0.96       872\n",
      "weighted avg       0.96      0.96      0.96       872\n",
      "\n",
      "============================\n",
      "XGB   TfIdfVectorizer\n",
      "============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       455\n",
      "           1       0.94      0.97      0.95       417\n",
      "\n",
      "    accuracy                           0.96       872\n",
      "   macro avg       0.96      0.96      0.96       872\n",
      "weighted avg       0.96      0.96      0.96       872\n",
      "\n",
      "============================\n",
      "RandomForest   CountVectorizer\n",
      "============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96       455\n",
      "           1       0.93      0.97      0.95       417\n",
      "\n",
      "    accuracy                           0.95       872\n",
      "   macro avg       0.95      0.95      0.95       872\n",
      "weighted avg       0.95      0.95      0.95       872\n",
      "\n",
      "============================\n",
      "AdaBoost   TfIdfVectorizer\n",
      "============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96       455\n",
      "           1       0.94      0.97      0.95       417\n",
      "\n",
      "    accuracy                           0.95       872\n",
      "   macro avg       0.95      0.95      0.95       872\n",
      "weighted avg       0.95      0.95      0.95       872\n",
      "\n",
      "============================\n",
      "CatBoost   TfIdfVectorizer\n",
      "============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       455\n",
      "           1       0.93      0.98      0.95       417\n",
      "\n",
      "    accuracy                           0.95       872\n",
      "   macro avg       0.95      0.96      0.95       872\n",
      "weighted avg       0.96      0.95      0.95       872\n",
      "\n",
      "============================\n",
      "GradientBoosting   TfIdfVectorizer\n",
      "============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       455\n",
      "           1       0.93      0.97      0.95       417\n",
      "\n",
      "    accuracy                           0.95       872\n",
      "   macro avg       0.95      0.95      0.95       872\n",
      "weighted avg       0.95      0.95      0.95       872\n",
      "\n",
      "============================\n",
      "AdaBoost   CountVectorizer\n",
      "============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       455\n",
      "           1       0.95      0.95      0.95       417\n",
      "\n",
      "    accuracy                           0.95       872\n",
      "   macro avg       0.95      0.95      0.95       872\n",
      "weighted avg       0.95      0.95      0.95       872\n",
      "\n",
      "============================\n",
      "RandomForest   TfIdfVectorizer\n",
      "============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       455\n",
      "           1       0.92      0.97      0.95       417\n",
      "\n",
      "    accuracy                           0.95       872\n",
      "   macro avg       0.95      0.95      0.95       872\n",
      "weighted avg       0.95      0.95      0.95       872\n",
      "\n",
      "============================\n",
      "DecisionTree   CountVectorizer\n",
      "============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       455\n",
      "           1       0.93      0.95      0.94       417\n",
      "\n",
      "    accuracy                           0.94       872\n",
      "   macro avg       0.94      0.94      0.94       872\n",
      "weighted avg       0.94      0.94      0.94       872\n",
      "\n",
      "============================\n",
      "DecisionTree   TfIdfVectorizer\n",
      "============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       455\n",
      "           1       0.94      0.76      0.84       417\n",
      "\n",
      "    accuracy                           0.86       872\n",
      "   macro avg       0.88      0.86      0.86       872\n",
      "weighted avg       0.88      0.86      0.86       872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfResults = dfResults.sort_values(by=['accuracy'], ascending=False)\n",
    "for i,r in dfResults.iterrows():\n",
    "    print('=================================')\n",
    "    print(r['model'],' ',r['vectorizer'])\n",
    "    print('=================================')\n",
    "\n",
    "    print(r['report'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testcaseanalyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d747574acc2e5296b08b0c8faa3bde07040d15676db5e5b0a47c53af9c4cfb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
